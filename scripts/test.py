"""
BraTSå¤šä¸­å¿ƒMAMLå…ƒæµ‹è¯•è„šæœ¬ï¼ˆå®Œæ•´ç‰ˆï¼‰
æ”¯æŒï¼šå¿«é€Ÿè¿ç§»ã€BraTSæ ‡å‡†è¯„ä¼°ã€å¤šä¸­å¿ƒæµ‹è¯•ã€å°æ ·æœ¬é€‚åº”
æ‰€æœ‰å‚æ•°é€šè¿‡é…ç½®æ–‡ä»¶å¯¼å…¥ï¼Œæ— éœ€å‘½ä»¤è¡Œå‚æ•°
"""

import torch
import torch.nn.functional as F
import argparse
import yaml
import os
import numpy as np
import nibabel as nib
from pathlib import Path
from tqdm import tqdm
import matplotlib.pyplot as plt
import json
import time
import copy
import warnings
import sys
warnings.filterwarnings('ignore')

from model import ResUNet
from maml import FirstOrderMAML
from dataloader import BraTSDataset


def load_config(config_path):
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    return config


def validate_config(config):
    """éªŒè¯é…ç½®æ–‡ä»¶çš„å¿…è¦å‚æ•°"""
    required_sections = ['data', 'model', 'maml', 'hardware', 'testing']
    for section in required_sections:
        if section not in config:
            raise ValueError(f"é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦éƒ¨åˆ†: {section}")

    # æ£€æŸ¥å¿…è¦å‚æ•°
    if 'checkpoint' not in config['testing']:
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘æµ‹è¯•checkpointè·¯å¾„: testing.checkpoint")

    if 'test_tasks' not in config['testing'] or not config['testing']['test_tasks']:
        raise ValueError("é…ç½®æ–‡ä»¶ä¸­ç¼ºå°‘æµ‹è¯•ä»»åŠ¡åˆ—è¡¨: testing.test_tasks")

    return True


def enforce_brats_hierarchy(pred_probs, threshold=0.5):
    """
    å¼ºåˆ¶æ‰§è¡ŒBraTSå±‚æ¬¡å…³ç³»ï¼šET âŠ† TC âŠ† WT
    å‚æ•°:
        pred_probs: [3, D, H, W] æˆ– [B, 3, D, H, W] æ¦‚ç‡å›¾
    è¿”å›: ä¿®æ­£åçš„äºŒå€¼åŒ–é¢„æµ‹
    """
    # äºŒå€¼åŒ–
    if isinstance(pred_probs, np.ndarray):
        pred_binary = (pred_probs > threshold).astype(np.float32)
    else:  # torch.Tensor
        pred_binary = (pred_probs > threshold).float()

    # å¤„ç†ä¸åŒç»´åº¦
    if pred_binary.ndim == 4:  # [3, D, H, W]
        wt, tc, et = pred_binary[0], pred_binary[1], pred_binary[2]
        tc_corrected = np.clip(tc + et, 0, 1) if isinstance(pred_binary, np.ndarray) else torch.clamp(tc + et, 0, 1)
        wt_corrected = np.clip(wt + tc_corrected, 0, 1) if isinstance(pred_binary, np.ndarray) else torch.clamp(wt + tc_corrected, 0, 1)
        result = np.stack([wt_corrected, tc_corrected, et], axis=0) if isinstance(pred_binary, np.ndarray) else torch.stack([wt_corrected, tc_corrected, et], dim=0)
    else:  # [B, 3, D, H, W]
        wt, tc, et = pred_binary[:, 0], pred_binary[:, 1], pred_binary[:, 2]
        tc_corrected = np.clip(tc + et, 0, 1) if isinstance(pred_binary, np.ndarray) else torch.clamp(tc + et, 0, 1)
        wt_corrected = np.clip(wt + tc_corrected, 0, 1) if isinstance(pred_binary, np.ndarray) else torch.clamp(wt + tc_corrected, 0, 1)
        result = np.stack([wt_corrected, tc_corrected, et], axis=1) if isinstance(pred_binary, np.ndarray) else torch.stack([wt_corrected, tc_corrected, et], dim=1)

    return result


def compute_brats_metrics(pred_logits, target, threshold=0.5):
    """
    æŒ‰ç…§BraTSå®˜æ–¹æ ‡å‡†è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    è¿”å›: {'WT': {'dice': ..., 'iou': ..., ...}, 'TC': ..., 'ET': ..., 'mean': ...}
    """
    with torch.no_grad():
        # 1. è·å–é¢„æµ‹æ¦‚ç‡
        pred_probs = torch.sigmoid(pred_logits)

        # 2. äºŒå€¼åŒ–
        pred_binary = (pred_probs > threshold).float()

        # 3. å¼ºåˆ¶æ‰§è¡Œå±‚æ¬¡å…³ç³»
        pred_binary = enforce_brats_hierarchy(pred_binary)

        # 4. ç¡®ä¿ç»´åº¦ä¸€è‡´
        if pred_binary.dim() == 4:
            pred_binary = pred_binary.unsqueeze(0)  # [1, 3, D, H, W]
            target = target.unsqueeze(0)

        # 5. åˆå§‹åŒ–ç»“æœ
        results = {}
        class_names = ['WT', 'TC', 'ET']

        # 6. é€ç±»åˆ«è®¡ç®—
        for idx, name in enumerate(class_names):
            pred_c = pred_binary[:, idx].flatten(start_dim=1)  # [B, D*H*W]
            target_c = target[:, idx].flatten(start_dim=1)

            batch_dice = []
            batch_iou = []
            batch_sens = []
            batch_spec = []

            # å¯¹æ¯ä¸ªæ ·æœ¬å•ç‹¬è®¡ç®—ï¼ˆBraTSæ ‡å‡†ï¼‰
            for b in range(pred_c.shape[0]):
                p = pred_c[b]
                t = target_c[b]

                # BraTS Diceè®¡ç®—
                intersection = (p * t).sum()
                union = p.sum() + t.sum()

                if t.sum() == 0:
                    dice = float('nan')
                elif union == 0:
                    dice = 0.0
                else:
                    dice = (2.0 * intersection) / union
                batch_dice.append(dice)

                # IoU
                iou = intersection / ((p + t).clamp(0, 1).sum() + 1e-8)
                batch_iou.append(iou)

                # æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§
                tp = (p * t).sum()
                fp = (p * (1 - t)).sum()
                fn = ((1 - p) * t).sum()
                tn = ((1 - p) * (1 - t)).sum()

                sens = tp / (tp + fn + 1e-8)
                spec = tn / (tn + fp + 1e-8)

                batch_sens.append(sens)
                batch_spec.append(spec)

            # å­˜å‚¨è¯¥ç±»åˆ«ç»“æœ
            results[name] = {
                'dice': torch.tensor(batch_dice).mean().item(),
                'dice_list': [d.item() if hasattr(d, 'item') else float(d) for d in batch_dice],
                'iou': torch.tensor(batch_iou).mean().item(),
                'sensitivity': torch.tensor(batch_sens).mean().item(),
                'specificity': torch.tensor(batch_spec).mean().item(),
                'volume_pred': pred_c.sum(dim=1).mean().item(),
                'volume_target': target_c.sum(dim=1).mean().item()
            }

        # 7. è®¡ç®—å¹³å‡æŒ‡æ ‡
        results['mean'] = {
            'dice': np.mean([results[n]['dice'] for n in class_names]),
            'iou': np.mean([results[n]['iou'] for n in class_names]),
            'sensitivity': np.mean([results[n]['sensitivity'] for n in class_names]),
            'specificity': np.mean([results[n]['specificity'] for n in class_names])
        }

        return results


def fast_adaptation(maml, adaptation_dataset, k_shot=3, inner_steps=10):
    """
    åœ¨æ–°ä¸­å¿ƒçš„å°‘é‡æ ·æœ¬ä¸Šå¿«é€Ÿé€‚åº”ï¼ˆå†…å­˜ä¼˜åŒ–ç‰ˆï¼‰
    """
    print(f"\nğŸš€ å¿«é€Ÿé€‚åº”: ä½¿ç”¨{k_shot}ä¸ªæ ·æœ¬è¿›è¡Œ{inner_steps}æ­¥é€‚åº”")

    # 0. é¦–å…ˆæ¸…ç†æ˜¾å­˜
    torch.cuda.empty_cache()

    # 1. é€‰æ‹©é€‚åº”æ ·æœ¬ï¼ˆä½†åªåŠ è½½ç´¢å¼•ï¼Œä¸ç«‹å³åŠ è½½æ•°æ®ï¼‰
    adapt_indices = []
    tumor_samples = []
    normal_samples = []

    # é¢„å…ˆæ‰«ææ ·æœ¬ï¼Œåªè®°å½•ç´¢å¼•
    for idx in range(len(adaptation_dataset)):
        # å¿«é€Ÿæ£€æŸ¥æ˜¯å¦æœ‰è‚¿ç˜¤ï¼ˆä½¿ç”¨è½»é‡æ–¹æ³•ï¼‰
        sample = adaptation_dataset[idx]
        if sample['label'].sum() > 0:  # æœ‰è‚¿ç˜¤çš„æ ·æœ¬
            tumor_samples.append(idx)
        else:
            normal_samples.append(idx)

    # ä¼˜å…ˆé€‰æ‹©æœ‰è‚¿ç˜¤çš„æ ·æœ¬
    if len(tumor_samples) >= k_shot:
        adapt_indices = np.random.choice(tumor_samples, k_shot, replace=False)
    else:
        adapt_indices = tumor_samples.copy()
        remaining = k_shot - len(tumor_samples)
        if remaining > 0 and len(normal_samples) > 0:
            additional = np.random.choice(normal_samples, min(remaining, len(normal_samples)), replace=False)
            adapt_indices.extend(additional)

    if len(adapt_indices) == 0:
        print("âš ï¸  æ²¡æœ‰å¯ç”¨äºé€‚åº”çš„æ ·æœ¬ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹")
        return maml.model

    print(f"  é€‰æ‹©çš„æ ·æœ¬ç´¢å¼•: {adapt_indices}")

    # 2. å…‹éš†æ¨¡å‹è¿›è¡Œé€‚åº”
    adapted_model = copy.deepcopy(maml.model)
    adapted_model.train()

    # 3. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰
    inner_optimizer = torch.optim.SGD(adapted_model.parameters(), lr=maml.inner_lr)

    for step in range(inner_steps):
        total_loss = 0.0
        inner_optimizer.zero_grad()

        # é€ä¸ªæ ·æœ¬å¤„ç†ï¼Œä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
        for idx in adapt_indices:
            # åŠ è½½å•ä¸ªæ ·æœ¬ï¼ˆé¿å…åŒæ—¶åŠ è½½æ‰€æœ‰æ ·æœ¬ï¼‰
            sample = adaptation_dataset[idx]

            # ä½¿ç”¨æ›´å°çš„è£å‰ªæˆ–ä¸‹é‡‡æ ·
            image = sample['image'].unsqueeze(0).to(maml.device)  # [1, 4, D, H, W]
            label = sample['label'].unsqueeze(0).to(maml.device)  # [1, 3, D, H, W]

            # å¯é€‰ï¼šå¦‚æœå›¾åƒå¤ªå¤§ï¼Œä½¿ç”¨ä¸­å¿ƒè£å‰ª
            if image.shape[2] * image.shape[3] * image.shape[4] > 128 * 128 * 64:  # å¤§çº¦8ç™¾ä¸‡ä½“ç´ 
                print(f"  æ ·æœ¬ {idx} å¤ªå¤§ï¼Œä½¿ç”¨ä¸­å¿ƒè£å‰ª")
                D, H, W = image.shape[2], image.shape[3], image.shape[4]
                crop_size = (min(128, D), min(128, H), min(128, W))
                d_start = (D - crop_size[0]) // 2
                h_start = (H - crop_size[1]) // 2
                w_start = (W - crop_size[2]) // 2

                image = image[:, :,
                        d_start:d_start + crop_size[0],
                        h_start:h_start + crop_size[1],
                        w_start:w_start + crop_size[2]]
                label = label[:, :,
                        d_start:d_start + crop_size[0],
                        h_start:h_start + crop_size[1],
                        w_start:w_start + crop_size[2]]

            # å‰å‘ä¼ æ’­
            with torch.cuda.amp.autocast():  # ä½¿ç”¨æ··åˆç²¾åº¦å‡å°‘å†…å­˜
                pred = adapted_model(image)
                loss = F.binary_cross_entropy_with_logits(pred, label)

                # ç¼©æ”¾æŸå¤±ï¼Œå› ä¸ºè¦ç´¯ç§¯æ¢¯åº¦
                loss = loss / len(adapt_indices)
                total_loss += loss.item()

                # åå‘ä¼ æ’­ï¼ˆç´¯ç§¯æ¢¯åº¦ï¼‰
                loss.backward()

            # æ¸…ç†å½“å‰æ ·æœ¬çš„æ˜¾å­˜
            del image, label, pred, loss
            torch.cuda.empty_cache()

        # æ›´æ–°å‚æ•°ï¼ˆä½¿ç”¨ç´¯ç§¯çš„æ¢¯åº¦ï¼‰
        inner_optimizer.step()

        # æ¸…ç†ä¼˜åŒ–å™¨çŠ¶æ€
        inner_optimizer.zero_grad(set_to_none=True)  # æ›´å½»åº•åœ°æ¸…ç†æ¢¯åº¦

        if (step + 1) % max(1, inner_steps // 5) == 0:
            print(f"    é€‚åº”æ­¥ [{step + 1}/{inner_steps}], Loss: {total_loss:.4f}")

        # æ¯æ­¥åæ¸…ç†æ˜¾å­˜
        torch.cuda.empty_cache()

    adapted_model.eval()
    print("  âœ… é€‚åº”å®Œæˆ")

    return adapted_model


def sliding_window_inference(model, image, window_size=(224, 224, 128),
                            overlap=0.5, device='cuda', threshold=0.5):
    """
    æ»‘åŠ¨çª—å£æ¨ç†ï¼ˆä¿®æ­£ç‰ˆï¼Œä½¿ç”¨Sigmoidï¼‰
    """
    C, D, H, W = image.shape
    num_classes = 3  # WT, TC, ET

    # æ­¥é•¿
    step_d = int(window_size[0] * (1 - overlap))
    step_h = int(window_size[1] * (1 - overlap))
    step_w = int(window_size[2] * (1 - overlap))

    # è¾“å‡ºç´¯ç§¯
    prediction = np.zeros((num_classes, D, H, W), dtype=np.float32)
    weight_map = np.zeros((D, H, W), dtype=np.float32)

    # ç”Ÿæˆçª—å£ä½ç½®
    positions = []
    for d in range(0, D - window_size[0] + 1, step_d):
        for h in range(0, H - window_size[1] + 1, step_h):
            for w in range(0, W - window_size[2] + 1, step_w):
                positions.append((d, h, w))

    # æ·»åŠ è¾¹ç•Œä½ç½®ç¡®ä¿è¦†ç›–
    if D > window_size[0]:
        for h in range(0, H - window_size[1] + 1, step_h):
            for w in range(0, W - window_size[2] + 1, step_w):
                positions.append((D - window_size[0], h, w))

    if H > window_size[1]:
        for d in range(0, D - window_size[0] + 1, step_d):
            for w in range(0, W - window_size[2] + 1, step_w):
                positions.append((d, H - window_size[1], w))

    if W > window_size[2]:
        for d in range(0, D - window_size[0] + 1, step_d):
            for h in range(0, H - window_size[1] + 1, step_h):
                positions.append((d, h, W - window_size[2]))

    # å»é‡
    positions = list(set(positions))

    print(f"  æ»‘åŠ¨çª—å£æ¨ç†: {len(positions)} ä¸ªçª—å£")

    # æ¨ç†æ¯ä¸ªçª—å£
    model.eval()
    with torch.no_grad():
        for d, h, w in tqdm(positions, desc='çª—å£æ¨ç†', leave=False):
            # æå–çª—å£
            patch = image[:,
                         d:d+window_size[0],
                         h:h+window_size[1],
                         w:w+window_size[2]]

            # æ¨ç†ï¼ˆä½¿ç”¨Sigmoidï¼‰
            patch_tensor = torch.FloatTensor(patch).unsqueeze(0).to(device)
            output = model(patch_tensor)  # [1, 3, D, H, W]
            output = torch.sigmoid(output)  # å…³é”®ä¿®æ”¹ï¼
            output = output.squeeze(0).cpu().numpy()

            # ç´¯ç§¯
            prediction[:,
                      d:d+window_size[0],
                      h:h+window_size[1],
                      w:w+window_size[2]] += output

            weight_map[d:d+window_size[0],
                      h:h+window_size[1],
                      w:w+window_size[2]] += 1

    # å¹³å‡
    weight_map = np.maximum(weight_map, 1)
    prediction = prediction / weight_map[np.newaxis, :, :, :]

    # å¼ºåˆ¶æ‰§è¡Œå±‚æ¬¡å…³ç³»
    prediction = enforce_brats_hierarchy(prediction, threshold)

    return prediction


def center_crop_inference(model, image, crop_size=(224, 224, 128),
                         device='cuda', threshold=0.5):
    """
    ä¸­å¿ƒcropæ¨ç†ï¼ˆä¿®æ­£ç‰ˆï¼‰
    """
    C, D, H, W = image.shape

    # è®¡ç®—ä¸­å¿ƒcrop
    d_start = max(0, (D - crop_size[0]) // 2)
    h_start = max(0, (H - crop_size[1]) // 2)
    w_start = max(0, (W - crop_size[2]) // 2)

    # Crop
    cropped = image[:,
                   d_start:d_start+crop_size[0],
                   h_start:h_start+crop_size[1],
                   w_start:w_start+crop_size[2]]

    # Paddingå¦‚æœéœ€è¦
    if cropped.shape[1:] != crop_size:
        pad_d = max(0, crop_size[0] - cropped.shape[1])
        pad_h = max(0, crop_size[1] - cropped.shape[2])
        pad_w = max(0, crop_size[2] - cropped.shape[3])

        cropped = np.pad(cropped,
                        [(0, 0), (0, pad_d), (0, pad_h), (0, pad_w)],
                        mode='constant')

    # æ¨ç†
    model.eval()
    with torch.no_grad():
        image_tensor = torch.FloatTensor(cropped).unsqueeze(0).to(device)
        output = model(image_tensor)
        output = torch.sigmoid(output)  # å…³é”®ä¿®æ”¹ï¼
        prediction = output.squeeze(0).cpu().numpy()

    # è¿˜åŸåˆ°åŸå§‹å°ºå¯¸
    full_prediction = np.zeros((3, D, H, W), dtype=np.float32)
    full_prediction[:,
                   d_start:d_start+crop_size[0],
                   h_start:h_start+crop_size[1],
                   w_start:w_start+crop_size[2]] = prediction[:, :cropped.shape[1],
                                                                  :cropped.shape[2],
                                                                  :cropped.shape[3]]

    # å¼ºåˆ¶æ‰§è¡Œå±‚æ¬¡å…³ç³»
    full_prediction = enforce_brats_hierarchy(full_prediction, threshold)

    return full_prediction


# def visualize_result_3d(image, label, prediction, save_path, patient_id, metrics=None):
#     """
#     å¯è§†åŒ–3Dåˆ†å‰²ç»“æœï¼ˆå¢å¼ºç‰ˆï¼‰
#     """
#     # é€‰æ‹©ä¸­é—´åˆ‡ç‰‡ï¼ˆ3ä¸ªä¸åŒå¹³é¢ï¼‰
#     d, h, w = image.shape[1:]
#
#     # è·å–æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«
#     pred_class = np.argmax(prediction, axis=0)
#     target_class = np.argmax(label, axis=0)
#
#     fig = plt.figure(figsize=(18, 10))
#
#     # å®šä¹‰ä¸‰ä¸ªå¹³é¢
#     planes = [
#         ('Axial', d // 2, 'axial'),
#         ('Coronal', h // 2, 'coronal'),
#         ('Sagittal', w // 2, 'sagittal')
#     ]
#
#     for row, (plane_name, slice_idx, plane_type) in enumerate(planes):
#         # æå–åˆ‡ç‰‡
#         if plane_type == 'axial':
#             img_slice = image[0, slice_idx, :, :]  # T1 modality
#             pred_slice = pred_class[slice_idx, :, :]
#             target_slice = target_class[slice_idx, :, :]
#         elif plane_type == 'coronal':
#             img_slice = image[0, :, slice_idx, :]
#             pred_slice = pred_class[:, slice_idx, :]
#             target_slice = target_class[:, slice_idx, :]
#         else:  # sagittal
#             img_slice = image[0, :, :, slice_idx]
#             pred_slice = pred_class[:, :, slice_idx]
#             target_slice = target_class[:, :, slice_idx]
#
#         # å›¾åƒ
#         ax1 = plt.subplot(3, 4, row*4 + 1)
#         ax1.imshow(img_slice, cmap='gray')
#         ax1.set_title(f'{plane_name} - T1', fontsize=11, fontweight='bold')
#         ax1.axis('off')
#
#         # çœŸå®æ ‡ç­¾
#         ax2 = plt.subplot(3, 4, row*4 + 2)
#         im2 = ax2.imshow(target_slice, cmap='jet', vmin=0, vmax=2)
#         ax2.set_title('Ground Truth', fontsize=11, fontweight='bold')
#         ax2.axis('off')
#
#         # é¢„æµ‹ç»“æœ
#         ax3 = plt.subplot(3, 4, row*4 + 3)
#         im3 = ax3.imshow(pred_slice, cmap='jet', vmin=0, vmax=2)
#         ax3.set_title('Prediction', fontsize=11, fontweight='bold')
#         ax3.axis('off')
#
#         # å åŠ æ˜¾ç¤º
#         ax4 = plt.subplot(3, 4, row*4 + 4)
#         ax4.imshow(img_slice, cmap='gray')
#         ax4.imshow(pred_slice, cmap='jet', alpha=0.5, vmin=0, vmax=2)
#         ax4.set_title('Overlay', fontsize=11, fontweight='bold')
#         ax4.axis('off')
#
#     # æ·»åŠ é¢œè‰²æ¡
#     plt.subplots_adjust(right=0.85)
#     cbar_ax = fig.add_axes([0.88, 0.15, 0.02, 0.7])
#     cbar = fig.colorbar(im3, cax=cbar_ax)
#     cbar.set_ticks([0, 1, 2])
#     cbar.set_ticklabels(['Background', 'TC/NCR', 'WT/ED'])
#
#     # æ·»åŠ æŒ‡æ ‡æ–‡æœ¬
#     if metrics:
#         metrics_text = f"Patient: {patient_id}\n\n"
#         metrics_text += "Dice Scores:\n"
#         for region in ['WT', 'TC', 'ET']:
#             metrics_text += f"  {region}: {metrics[region]['dice']:.4f}\n"
#         metrics_text += f"\nMean Dice: {metrics['mean']['dice']:.4f}"
#
#         fig.text(0.02, 0.5, metrics_text, fontsize=10,
#                 verticalalignment='center', family='monospace',
#                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
#
#     plt.suptitle(f'BraTS Segmentation Results - {patient_id}',
#                 fontsize=14, fontweight='bold')
#     plt.tight_layout(rect=[0, 0, 0.85, 0.95])
#     plt.savefig(save_path, dpi=150, bbox_inches='tight')
#     plt.close()

def visualize_result_3d(image, label, prediction, save_path, patient_id, metrics=None):
    """
    å¯è§†åŒ–3Dåˆ†å‰²ç»“æœï¼ˆä¿®æ­£ç‰ˆ - å¤šæ ‡ç­¾æ˜¾ç¤ºï¼‰
    """
    d, h, w = image.shape[1:]

    # âš ï¸ å…³é”®ä¿®å¤ï¼šä¸ä½¿ç”¨argmaxï¼
    # BraTSæ ‡ç­¾æ˜¯å¤šæ ‡ç­¾ï¼Œéœ€è¦åˆ†åˆ«æ˜¾ç¤º

    fig = plt.figure(figsize=(20, 12))

    # é€‰æ‹©ä¸‰ä¸ªæ­£äº¤å¹³é¢
    planes = [
        ('Axial', d // 2, 0),
        ('Coronal', h // 2, 1),
        ('Sagittal', w // 2, 2)
    ]

    class_names = ['WT', 'TC', 'ET']
    class_colors = ['Reds', 'Greens', 'Blues']

    for row, (plane_name, slice_idx, axis) in enumerate(planes):
        # æå–åˆ‡ç‰‡
        if axis == 0:  # Axial
            img_slice = image[0, slice_idx, :, :]
            label_slices = [label[i, slice_idx, :, :] for i in range(3)]
            pred_slices = [prediction[i, slice_idx, :, :] for i in range(3)]
        elif axis == 1:  # Coronal
            img_slice = image[0, :, slice_idx, :]
            label_slices = [label[i, :, slice_idx, :] for i in range(3)]
            pred_slices = [prediction[i, :, slice_idx, :] for i in range(3)]
        else:  # Sagittal
            img_slice = image[0, :, :, slice_idx]
            label_slices = [label[i, :, :, slice_idx] for i in range(3)]
            pred_slices = [prediction[i, :, :, slice_idx] for i in range(3)]

        # ç¬¬1åˆ—ï¼šåŸå§‹å›¾åƒ
        ax1 = plt.subplot(3, 5, row * 5 + 1)
        ax1.imshow(img_slice, cmap='gray')
        ax1.set_title(f'{plane_name}\nT1', fontsize=10, fontweight='bold')
        ax1.axis('off')

        # ç¬¬2åˆ—ï¼šGTç»„åˆæ˜¾ç¤ºï¼ˆRGBï¼‰
        ax2 = plt.subplot(3, 5, row * 5 + 2)
        gt_rgb = np.zeros((*img_slice.shape, 3))
        gt_rgb[..., 0] = label_slices[0]  # WT -> Red
        gt_rgb[..., 1] = label_slices[1]  # TC -> Green
        gt_rgb[..., 2] = label_slices[2]  # ET -> Blue
        ax2.imshow(img_slice, cmap='gray')
        ax2.imshow(gt_rgb, alpha=0.5)
        ax2.set_title('Ground Truth\n(WT+TC+ET)', fontsize=10, fontweight='bold')
        ax2.axis('off')

        # ç¬¬3åˆ—ï¼šé¢„æµ‹ç»„åˆæ˜¾ç¤ºï¼ˆRGBï¼‰
        ax3 = plt.subplot(3, 5, row * 5 + 3)
        pred_rgb = np.zeros((*img_slice.shape, 3))
        pred_rgb[..., 0] = pred_slices[0]  # WT -> Red
        pred_rgb[..., 1] = pred_slices[1]  # TC -> Green
        pred_rgb[..., 2] = pred_slices[2]  # ET -> Blue
        ax3.imshow(img_slice, cmap='gray')
        ax3.imshow(pred_rgb, alpha=0.5)
        ax3.set_title('Prediction\n(WT+TC+ET)', fontsize=10, fontweight='bold')
        ax3.axis('off')

        # ç¬¬4åˆ—ï¼šåˆ†åˆ«æ˜¾ç¤ºä¸‰ä¸ªç±»åˆ«ï¼ˆGT vs Predï¼‰
        ax4 = plt.subplot(3, 5, row * 5 + 4)
        # åˆ›å»ºä¸‰é€šé“å›¾ï¼šR=WT, G=TC, B=ET
        comparison = np.zeros((*img_slice.shape, 3))
        for i, (gt, pred) in enumerate(zip(label_slices, pred_slices)):
            # TP: ç™½è‰², FP: é¢„æµ‹é¢œè‰², FN: GTé¢œè‰²åŠé€æ˜
            tp = (gt > 0.5) & (pred > 0.5)
            fp = (gt <= 0.5) & (pred > 0.5)
            fn = (gt > 0.5) & (pred <= 0.5)

            comparison[tp, i] = 1.0  # æ­£ç¡®é¢„æµ‹
            comparison[fp, i] = 0.7  # å‡é˜³æ€§ï¼ˆæ©™è‰²ç³»ï¼‰
            comparison[fn, i] = 0.3  # å‡é˜´æ€§ï¼ˆæš—è‰²ç³»ï¼‰

        ax4.imshow(comparison)
        ax4.set_title('Comparison\n(White=TP)', fontsize=10, fontweight='bold')
        ax4.axis('off')

        # ç¬¬5åˆ—ï¼šå•ç‹¬æ˜¾ç¤ºETï¼ˆå› ä¸ºETå®¹æ˜“æ¼æ‰ï¼‰
        ax5 = plt.subplot(3, 5, row * 5 + 5)
        ax5.imshow(img_slice, cmap='gray')

        # ETçš„GTå’Œé¢„æµ‹
        et_combined = np.zeros((*img_slice.shape, 3))
        et_combined[label_slices[2] > 0.5, 0] = 1.0  # GTçº¢è‰²
        et_combined[pred_slices[2] > 0.5, 1] = 1.0  # Predç»¿è‰²
        # é‡å éƒ¨åˆ†ä¼šå˜æˆé»„è‰²

        ax5.imshow(et_combined, alpha=0.8)
        ax5.set_title(f'ET Only\n(GT={label_slices[2].sum():.0f})',
                      fontsize=10, fontweight='bold')
        ax5.axis('off')

    # æ·»åŠ æŒ‡æ ‡æ–‡æœ¬
    if metrics:
        metrics_text = f"Patient: {patient_id}\n\n"
        metrics_text += "Dice Scores:\n"
        for region in ['WT', 'TC', 'ET']:
            metrics_text += f"  {region}: {metrics[region]['dice']:.4f}\n"
            if region == 'ET' and metrics[region]['dice'] == 0:
                metrics_text += f"       âš ï¸ ET prediction is empty!\n"
        metrics_text += f"\nMean: {metrics['mean']['dice']:.4f}\n"
        metrics_text += f"\nLegend:\n"
        metrics_text += f"  Red=WT, Green=TC, Blue=ET\n"
        metrics_text += f"  White=Correct Prediction\n"
        metrics_text += f"  Orange=False Positive\n"
        metrics_text += f"  Dark=False Negative"

        fig.text(0.02, 0.5, metrics_text, fontsize=9,
                 verticalalignment='center', family='monospace',
                 bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))

    plt.suptitle(f'BraTS Multi-Label Segmentation - {patient_id}',
                 fontsize=14, fontweight='bold')
    plt.tight_layout(rect=[0.15, 0, 1, 0.96])
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    plt.close()


def restore_to_original_size(prediction, crop_info, original_shape):
    """
    å°†è£å‰ªåçš„é¢„æµ‹æ¢å¤åˆ°åŸå§‹å°ºå¯¸

    å‚æ•°:
        prediction: [3, D_crop, H_crop, W_crop] è£å‰ªåçš„é¢„æµ‹
        crop_info: åŒ…å«crop_startå’Œoriginal_shapeçš„å­—å…¸
        original_shape: (D, H, W) åŸå§‹å°ºå¯¸

    è¿”å›:
        restored: [3, D, H, W] æ¢å¤åˆ°åŸå§‹å°ºå¯¸çš„é¢„æµ‹
    """
    # åˆ›å»ºåŸå§‹å°ºå¯¸çš„å…¨é›¶æ•°ç»„
    restored = np.zeros((3, *original_shape), dtype=np.float32)

    # è·å–cropä½ç½®
    crop_start = crop_info.get('crop_start', None)

    if crop_start is None:
        # å¦‚æœæ²¡æœ‰crop_startä¿¡æ¯ï¼Œå‡è®¾æ˜¯ä¸­å¿ƒcrop
        d_start = (original_shape[0] - prediction.shape[1]) // 2
        h_start = (original_shape[1] - prediction.shape[2]) // 2
        w_start = (original_shape[2] - prediction.shape[3]) // 2
        crop_start = [max(0, d_start), max(0, h_start), max(0, w_start)]

    # è®¡ç®—å®é™…å¯ä»¥æ”¾ç½®çš„å°ºå¯¸
    d_size = min(prediction.shape[1], original_shape[0] - crop_start[0])
    h_size = min(prediction.shape[2], original_shape[1] - crop_start[1])
    w_size = min(prediction.shape[3], original_shape[2] - crop_start[2])

    # å°†é¢„æµ‹æ”¾å›åŸå§‹ä½ç½®
    restored[:,
    crop_start[0]:crop_start[0] + d_size,
    crop_start[1]:crop_start[1] + h_size,
    crop_start[2]:crop_start[2] + w_size] = prediction[:,
                                            :d_size,
                                            :h_size,
                                            :w_size]

    return restored


def whole_volume_inference(model, image, crop_size=(224, 224, 128),
                           device='cuda', threshold=0.5):
    """
    æ•´ä¸ªä½“ç§¯çš„æ¨ç†ï¼ˆä½¿ç”¨æ»‘åŠ¨çª—å£ + æ¢å¤åŸå§‹å°ºå¯¸ï¼‰

    è¿™ä¸ªå‡½æ•°ä¸åšä»»ä½•è£å‰ªï¼Œç›´æ¥å¤„ç†æ•´ä¸ªä½“ç§¯
    """
    C, D, H, W = image.shape

    # å¦‚æœå›¾åƒå°äºcrop_sizeï¼Œç›´æ¥æ¨ç†
    if D <= crop_size[0] and H <= crop_size[1] and W <= crop_size[2]:
        # Paddingåˆ°crop_size
        padded = np.zeros((C, *crop_size), dtype=np.float32)
        padded[:, :D, :H, :W] = image

        model.eval()
        with torch.no_grad():
            img_tensor = torch.FloatTensor(padded).unsqueeze(0).to(device)
            output = model(img_tensor)
            output = torch.sigmoid(output)
            pred = output.squeeze(0).cpu().numpy()

        # è£å‰ªå›åŸå§‹å°ºå¯¸
        pred = pred[:, :D, :H, :W]

        # å¼ºåˆ¶å±‚æ¬¡å…³ç³»
        pred = enforce_brats_hierarchy(pred, threshold)

        return pred

    # å¦åˆ™ä½¿ç”¨æ»‘åŠ¨çª—å£
    return sliding_window_inference(
        model, image, crop_size,
        overlap=0.5, device=device, threshold=threshold
    )
def save_brats_prediction(pred_probs, save_path, threshold=0.5):
    """
    ä¿å­˜é¢„æµ‹ç»“æœä¸ºBraTSæ ¼å¼çš„NIfTIæ–‡ä»¶
    æ ‡ç­¾æ˜ å°„: 0-èƒŒæ™¯, 1-åæ­»(NCR), 2-æ°´è‚¿(ED), 4-å¢å¼º(ET)
    """
    try:
        # äºŒå€¼åŒ–
        pred_binary = (pred_probs > threshold).astype(np.float32)

        # å¼ºåˆ¶æ‰§è¡Œå±‚æ¬¡å…³ç³»
        pred_binary = enforce_brats_hierarchy(pred_binary)

        # è½¬æ¢ä¸ºBraTSæ ‡ç­¾æ ¼å¼
        wt, tc, et = pred_binary[0], pred_binary[1], pred_binary[2]

        output = np.zeros(wt.shape, dtype=np.uint8)

        # BraTSæ ‡ç­¾æ ¼å¼
        output[wt == 1] = 2  # æ°´è‚¿åŒºåŸŸ
        output[tc == 1] = 1  # è‚¿ç˜¤æ ¸å¿ƒï¼ˆåæ­»ï¼‰
        output[et == 1] = 4  # å¢å¼ºè‚¿ç˜¤

        # ç¡®ä¿å±‚æ¬¡å…³ç³»ï¼ˆå†æ¬¡æ£€æŸ¥ï¼‰
        # å¢å¼ºè‚¿ç˜¤åº”è¯¥åœ¨è‚¿ç˜¤æ ¸å¿ƒå†…
        output[(et == 1) & (tc == 0)] = 4  # åº”è¯¥ä¸ä¼šå‘ç”Ÿ

        # åˆ›å»ºNIfTIå›¾åƒ
        nii_img = nib.Nifti1Image(output, affine=np.eye(4))
        nib.save(nii_img, save_path)

        return True
    except Exception as e:
        print(f"è­¦å‘Š: ä¿å­˜NIfTIå¤±è´¥: {e}")
        return False


# def test_single_task(maml, config, task_name, output_base_dir):
#     """
#     æµ‹è¯•å•ä¸ªä»»åŠ¡ï¼ˆæ”¯æŒå¿«é€Ÿé€‚åº”ï¼‰
#     """
#     print(f"\n{'='*70}")
#     print(f"æµ‹è¯•ä»»åŠ¡: {task_name}")
#     print('='*70)
#
#     # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
#     test_dataset = BraTSDataset(
#         data_root=config['data']['data_root'],
#         task_name=task_name,
#         mode='test',
#         crop_size=tuple(config['data']['crop_size']),
#         crop_strategy='smart_random',
#         normalize=True,
#         augment_type='none'
#     )
#
#     if len(test_dataset) == 0:
#         print(f"âš ï¸  {task_name} æ²¡æœ‰æµ‹è¯•æ•°æ®")
#         return None
#
#     print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")
#
#     # åˆ›å»ºè¾“å‡ºç›®å½•
#     task_output_dir = Path(output_base_dir) / task_name
#     task_output_dir.mkdir(parents=True, exist_ok=True)
#
#     vis_dir = task_output_dir / 'visualizations'
#     pred_dir = task_output_dir / 'predictions'
#
#     if config['testing']['visualization']:
#         vis_dir.mkdir(exist_ok=True)
#     if config['testing']['save_predictions']:
#         pred_dir.mkdir(exist_ok=True)
#
#     # ========== å¿«é€Ÿé€‚åº”é˜¶æ®µ ==========
#     inference_model = maml.model
#     adaptation_info = {"adapted": False, "k_shot": 0, "steps": 0}
#
#     if config['testing']['enable_adaptation']:
#         k_shot = config['testing']['adaptation_k_shot']
#         inner_steps = config['testing']['adaptation_inner_steps']
#
#         # åˆ›å»ºé€‚åº”æ•°æ®é›†ï¼ˆä»æµ‹è¯•é›†ä¸­é‡‡æ ·ï¼‰
#         adapt_dataset = BraTSDataset(
#             data_root=config['data']['data_root'],
#             task_name=task_name,
#             mode='test',
#             crop_size=tuple(config['data']['crop_size']),
#             crop_strategy='smart_random',
#             normalize=True,
#             augment_type='none'
#         )
#
#         # å¿«é€Ÿé€‚åº”
#         adapted_model = fast_adaptation(
#             maml, adapt_dataset,
#             k_shot=k_shot,
#             inner_steps=inner_steps
#         )
#
#         inference_model = adapted_model
#         adaptation_info = {"adapted": True, "k_shot": k_shot, "steps": inner_steps}
#
#     # ========== æ¨ç†é…ç½® ==========
#     inference_mode = config['testing']['inference']['mode']
#     window_size = tuple(config['data']['crop_size'])
#     overlap = config['testing']['inference']['overlap']
#     threshold = config['testing']['threshold']
#
#     # ========== æµ‹è¯•æ¯ä¸ªæ ·æœ¬ ==========
#     all_metrics = []
#     processing_times = []
#     failed_samples = []
#
#     for idx in tqdm(range(len(test_dataset)), desc=f'æµ‹è¯• {task_name}'):
#         sample = test_dataset[idx]
#
#         image = sample['image'].numpy()  # [4, D, H, W] - è£å‰ªåçš„
#         label = sample['label'].numpy()  # [3, D, H, W] - è£å‰ªåçš„
#         patient_id = sample['patient_id']
#         crop_info = sample['crop_info']
#         original_shape = sample['original_shape']  # âš ï¸ è·å–åŸå§‹å°ºå¯¸
#
#         try:
#             start_time = time.time()
#
#             # æ¨ç†ï¼ˆåœ¨è£å‰ªåçš„å›¾åƒä¸Šï¼‰
#             if inference_mode == 'sliding_window':
#                 prediction_cropped = sliding_window_inference(
#                     inference_model, image, window_size,
#                     overlap, maml.device, threshold
#                 )
#             else:
#                 prediction_cropped = center_crop_inference(
#                     inference_model, image, window_size,
#                     maml.device, threshold
#                 )
#
#             # âš ï¸ æ¢å¤åˆ°åŸå§‹å°ºå¯¸
#             prediction = restore_to_original_size(
#                 prediction_cropped,
#                 crop_info,
#                 original_shape
#             )
#
#             processing_time = time.time() - start_time
#
#             # âš ï¸ æ³¨æ„ï¼šè¿™é‡Œçš„labelä¹Ÿéœ€è¦æ¢å¤åˆ°åŸå§‹å°ºå¯¸æ¥è®¡ç®—æŒ‡æ ‡
#             # ä½†å¦‚æœåŸå§‹æ ‡ç­¾å¤ªå¤§ï¼Œå¯ä»¥åªåœ¨cropåŒºåŸŸè®¡ç®—
#             # è¿™é‡Œæˆ‘ä»¬ç®€åŒ–å¤„ç†ï¼Œåªåœ¨cropåŒºåŸŸè®¡ç®—æŒ‡æ ‡
#
#             # è®¡ç®—æŒ‡æ ‡ï¼ˆä½¿ç”¨è£å‰ªåŒºåŸŸï¼‰
#             pred_logits = torch.FloatTensor(prediction_cropped)
#             target_tensor = torch.FloatTensor(label).unsqueeze(0)
#
#             metrics = compute_brats_metrics(
#                 pred_logits.unsqueeze(0),
#                 target_tensor,
#                 threshold
#             )
#
#             metrics['patient_id'] = patient_id
#             metrics['processing_time'] = processing_time
#             all_metrics.append(metrics)
#
#             # ä¿å­˜é¢„æµ‹ç»“æœ
#             if config['testing']['save_predictions']:
#                 pred_path = pred_dir / f"{patient_id}_pred.nii.gz"
#                 save_brats_prediction(prediction, str(pred_path), threshold)  # ä½¿ç”¨æ¢å¤åçš„
#
#                 # å¯è§†åŒ–ï¼ˆä½¿ç”¨è£å‰ªåŒºåŸŸï¼Œå› ä¸ºlabelä¹Ÿæ˜¯è£å‰ªçš„ï¼‰
#             if config['testing']['visualization']:
#                 vis_path = vis_dir / f"{patient_id}_result.png"
#                 visualize_result_3d(
#                     image, label, prediction_cropped,  # ä½¿ç”¨è£å‰ªç‰ˆæœ¬
#                     str(vis_path), patient_id, metrics
#                 )
#
#             # æ‰“å°å•ä¸ªæ ·æœ¬ç»“æœ
#             if config['testing']['verbose']:
#                 print(f"\n  {patient_id}:")
#                 print(f"    WT Dice: {metrics['WT']['dice']:.4f}")
#                 print(f"    TC Dice: {metrics['TC']['dice']:.4f}")
#                 print(f"    ET Dice: {metrics['ET']['dice']:.4f}")
#                 print(f"    Mean Dice: {metrics['mean']['dice']:.4f}")
#                 print(f"    Time: {processing_time:.2f}s")
#
#         except Exception as e:
#             print(f"\nâš ï¸  å¤„ç† {patient_id} æ—¶å‡ºé”™: {e}")
#             failed_samples.append(patient_id)
#             continue
#
#     # ========== æ±‡æ€»ç»“æœ ==========
#     if len(all_metrics) == 0:
#         print(f"âŒ  {task_name} æ²¡æœ‰æˆåŠŸå¤„ç†çš„æ ·æœ¬")
#         return None
#
#     # è®¡ç®—å¹³å‡æŒ‡æ ‡
#     summary = {
#         'task_name': task_name,
#         'num_samples': len(all_metrics),
#         'failed_samples': failed_samples,
#         'adaptation': adaptation_info,
#         'avg_processing_time': float(np.mean(processing_times)),
#         'metrics': {}
#     }
#
#     class_names = ['WT', 'TC', 'ET']
#     for name in class_names:
#         dice_values = [m[name]['dice'] for m in all_metrics]
#         summary['metrics'][name] = {
#             'dice_mean': float(np.mean(dice_values)),
#             'dice_std': float(np.std(dice_values)),
#             'dice_min': float(np.min(dice_values)),
#             'dice_max': float(np.max(dice_values)),
#             'sensitivity_mean': float(np.mean([m[name]['sensitivity'] for m in all_metrics])),
#             'specificity_mean': float(np.mean([m[name]['specificity'] for m in all_metrics]))
#         }
#
#     # æ€»ä½“å¹³å‡
#     summary['metrics']['overall'] = {
#         'dice_mean': float(np.mean([summary['metrics'][n]['dice_mean'] for n in class_names])),
#         'dice_std': float(np.mean([summary['metrics'][n]['dice_std'] for n in class_names]))
#     }
#
#     # æ‰“å°ç»“æœ
#     print(f"\n{'='*70}")
#     print(f"{task_name} æµ‹è¯•ç»“æœæ±‡æ€»")
#     print('='*70)
#     print(f"æˆåŠŸå¤„ç†: {len(all_metrics)}/{len(test_dataset)} ä¸ªæ ·æœ¬")
#     if failed_samples:
#         print(f"å¤±è´¥æ ·æœ¬: {', '.join(failed_samples)}")
#
#     print(f"\nå¹³å‡å¤„ç†æ—¶é—´: {summary['avg_processing_time']:.2f}s")
#
#     print(f"\n{'æŒ‡æ ‡':<15} {'WT':>10} {'TC':>10} {'ET':>10}")
#     print("-" * 55)
#
#     for metric in ['dice_mean', 'dice_std', 'sensitivity_mean', 'specificity_mean']:
#         metric_name = metric.replace('_mean', '').replace('_std', ' std').title()
#         values = [summary['metrics'][n][metric] for n in class_names]
#         print(f"{metric_name:<15} {values[0]:>10.4f} {values[1]:>10.4f} {values[2]:>10.4f}")
#
#     print(f"\næ€»ä½“å¹³å‡Dice: {summary['metrics']['overall']['dice_mean']:.4f}")
#     print('='*70)
#
#     # ä¿å­˜è¯¦ç»†ç»“æœ
#     detailed_results = {
#         'summary': summary,
#         'all_metrics': all_metrics,
#         'config': config['testing']
#     }
#
#     result_file = task_output_dir / f"results_{task_name}.json"
#     with open(result_file, 'w') as f:
#         json.dump(detailed_results, f, indent=2)
#
#     print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
#
#     return summary

def test_single_task(maml, config, task_name, output_base_dir):
    """
    æµ‹è¯•å•ä¸ªä»»åŠ¡ï¼ˆæ”¯æŒå¿«é€Ÿé€‚åº”ï¼‰- ä¿®æ­£ç‰ˆï¼Œåˆ†åˆ«è®°å½•é€‚åº”æ ·æœ¬å’Œæµ‹è¯•æ ·æœ¬ç»“æœ
    """
    print(f"\n{'=' * 70}")
    print(f"æµ‹è¯•ä»»åŠ¡: {task_name}")
    print('=' * 70)

    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    test_dataset = BraTSDataset(
        data_root=config['data']['data_root'],
        task_name=task_name,
        mode='test',
        crop_size=tuple(config['data']['crop_size']),
        crop_strategy='smart_random',
        normalize=True,
        augment_type='none'
    )

    if len(test_dataset) == 0:
        print(f"âš ï¸  {task_name} æ²¡æœ‰æµ‹è¯•æ•°æ®")
        return None

    print(f"æµ‹è¯•æ ·æœ¬æ•°: {len(test_dataset)}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    task_output_dir = Path(output_base_dir) / task_name
    task_output_dir.mkdir(parents=True, exist_ok=True)

    # ========== æ•°æ®åˆ†å‰²ï¼šé€‚åº”æ ·æœ¬ vs æµ‹è¯•æ ·æœ¬ ==========
    total_samples = len(test_dataset)
    k_shot = config['testing']['adaptation_k_shot']

    # å¦‚æœæ ·æœ¬æ•°ä¸è¶³ä»¥åˆ†å‰²ï¼Œè°ƒæ•´k_shot
    if k_shot >= total_samples:
        print(f"âš ï¸  k_shot({k_shot}) >= æ€»æ ·æœ¬æ•°({total_samples})ï¼Œä½¿ç”¨æ‰€æœ‰æ ·æœ¬è¿›è¡Œé€‚åº”")
        k_shot = max(1, total_samples // 2)  # è‡³å°‘ä¿ç•™ä¸€åŠæ ·æœ¬ç”¨äºæµ‹è¯•

    # å›ºå®šéšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    import random
    random_seed = config['testing'].get('random_seed', 42)
    random.seed(random_seed)
    np.random.seed(random_seed)
    torch.manual_seed(random_seed)

    # ä¼˜å…ˆé€‰æ‹©æœ‰è‚¿ç˜¤çš„æ ·æœ¬ä½œä¸ºé€‚åº”æ ·æœ¬
    print("  æ‰«ææ ·æœ¬ï¼ŒæŸ¥æ‰¾æœ‰è‚¿ç˜¤çš„æ ·æœ¬...")
    tumor_indices = []
    normal_indices = []

    for idx in range(total_samples):
        sample = test_dataset[idx]
        if sample['label'].sum() > 0:  # æœ‰è‚¿ç˜¤
            tumor_indices.append(idx)
        else:
            normal_indices.append(idx)

    print(f"  æœ‰è‚¿ç˜¤æ ·æœ¬: {len(tumor_indices)}ä¸ª, æ­£å¸¸æ ·æœ¬: {len(normal_indices)}ä¸ª")

    # é€‰æ‹©é€‚åº”æ ·æœ¬
    adapt_indices = []
    if len(tumor_indices) >= k_shot:
        adapt_indices = random.sample(tumor_indices, k_shot)
    else:
        adapt_indices = tumor_indices.copy()
        remaining = k_shot - len(tumor_indices)
        if remaining > 0 and len(normal_indices) >= remaining:
            adapt_indices.extend(random.sample(normal_indices, remaining))
        else:
            # å¦‚æœæ ·æœ¬ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰æ ·æœ¬
            adapt_indices = list(range(min(k_shot, total_samples)))

    # æµ‹è¯•æ ·æœ¬æ˜¯å‰©ä½™çš„æ ·æœ¬
    all_indices = set(range(total_samples))
    adapt_set = set(adapt_indices)
    test_eval_indices = list(all_indices - adapt_set)

    print(f"  é€‚åº”æ ·æœ¬: {len(adapt_indices)}ä¸ª (ç´¢å¼•: {sorted(adapt_indices)})")
    print(f"  æµ‹è¯•æ ·æœ¬: {len(test_eval_indices)}ä¸ª (ç´¢å¼•: {sorted(test_eval_indices)})")

    # åˆ›å»ºæ•°æ®é›†åŒ…è£…å™¨
    class IndexedDataset(torch.utils.data.Dataset):
        def __init__(self, original_dataset, indices):
            self.original_dataset = original_dataset
            self.indices = indices

        def __len__(self):
            return len(self.indices)

        def __getitem__(self, idx):
            original_idx = self.indices[idx]
            sample = self.original_dataset[original_idx]
            sample['original_idx'] = original_idx
            return sample

    adapt_dataset = IndexedDataset(test_dataset, adapt_indices)
    test_eval_dataset = IndexedDataset(test_dataset, test_eval_indices)

    # ========== åˆ›å»ºå¯è§†åŒ–ç›®å½• ==========
    vis_dir = task_output_dir / 'visualizations'
    pred_dir = task_output_dir / 'predictions'

    if config['testing']['visualization']:
        vis_dir.mkdir(exist_ok=True)
        # ä¸ºé€‚åº”æ ·æœ¬å’Œæµ‹è¯•æ ·æœ¬åˆ†åˆ«åˆ›å»ºå­ç›®å½•
        vis_adapt_dir = vis_dir / 'adaptation_samples'
        vis_test_dir = vis_dir / 'test_samples'
        vis_adapt_dir.mkdir(exist_ok=True)
        vis_test_dir.mkdir(exist_ok=True)

    if config['testing']['save_predictions']:
        pred_dir.mkdir(exist_ok=True)
        pred_adapt_dir = pred_dir / 'adaptation_samples'
        pred_test_dir = pred_dir / 'test_samples'
        pred_adapt_dir.mkdir(exist_ok=True)
        pred_test_dir.mkdir(exist_ok=True)

    # ========== å¿«é€Ÿé€‚åº”é˜¶æ®µ ==========
    inference_model = maml.model
    adaptation_info = {"adapted": False, "k_shot": 0, "steps": 0, "adapt_indices": []}

    if config['testing']['enable_adaptation']:
        k_shot_actual = len(adapt_dataset)
        inner_steps = config['testing']['adaptation_inner_steps']

        print(f"\nğŸš€ å¿«é€Ÿé€‚åº”é˜¶æ®µ")
        print(f"  ä½¿ç”¨ {k_shot_actual} ä¸ªæ ·æœ¬è¿›è¡Œ {inner_steps} æ­¥é€‚åº”")
        print(f"  é€‚åº”æ ·æœ¬ç´¢å¼•: {sorted(adapt_indices)}")

        # å¿«é€Ÿé€‚åº”
        adapted_model = fast_adaptation(
            maml, adapt_dataset,
            k_shot=k_shot_actual,
            inner_steps=inner_steps
        )

        inference_model = adapted_model
        adaptation_info = {
            "adapted": True,
            "k_shot": k_shot_actual,
            "steps": inner_steps,
            "adapt_indices": adapt_indices
        }

    # ========== æ¨ç†é…ç½® ==========
    inference_mode = config['testing']['inference']['mode']
    window_size = tuple(config['data']['crop_size'])
    overlap = config['testing']['inference']['overlap']
    threshold = config['testing']['threshold']

    # ========== åˆ†åˆ«æµ‹è¯•é€‚åº”æ ·æœ¬å’Œæµ‹è¯•æ ·æœ¬ ==========
    adapt_metrics = []
    test_metrics = []
    all_metrics = []  # ä¿æŒå…¼å®¹æ€§ï¼Œæ‰€æœ‰æ ·æœ¬çš„ç»“æœ
    processing_times = []
    failed_samples = []

    print(f"\nğŸ“Š æµ‹è¯•é˜¶æ®µ")
    print(f"  1. æµ‹è¯•é€‚åº”æ ·æœ¬ ({len(adapt_dataset)}ä¸ª)")

    # æµ‹è¯•é€‚åº”æ ·æœ¬
    for idx in tqdm(range(len(adapt_dataset)), desc='æµ‹è¯•é€‚åº”æ ·æœ¬'):
        sample = adapt_dataset[idx]
        original_idx = sample['original_idx']

        image = sample['image'].numpy()
        label = sample['label'].numpy()
        patient_id = sample['patient_id']
        crop_info = sample['crop_info']
        original_shape = sample['original_shape']

        try:
            start_time = time.time()

            # æ¨ç†
            if inference_mode == 'sliding_window':
                prediction_cropped = sliding_window_inference(
                    inference_model, image, window_size,
                    overlap, maml.device, threshold
                )
            else:
                prediction_cropped = center_crop_inference(
                    inference_model, image, window_size,
                    maml.device, threshold
                )

            # æ¢å¤åˆ°åŸå§‹å°ºå¯¸
            prediction = restore_to_original_size(
                prediction_cropped,
                crop_info,
                original_shape
            )

            processing_time = time.time() - start_time
            processing_times.append(processing_time)

            # è®¡ç®—æŒ‡æ ‡
            pred_logits = torch.FloatTensor(prediction_cropped)
            target_tensor = torch.FloatTensor(label).unsqueeze(0)

            metrics = compute_brats_metrics(
                pred_logits.unsqueeze(0),
                target_tensor,
                threshold
            )

            metrics['patient_id'] = patient_id
            metrics['original_idx'] = original_idx
            metrics['sample_type'] = 'adaptation'  # æ ‡è®°ä¸ºé€‚åº”æ ·æœ¬
            metrics['processing_time'] = processing_time

            adapt_metrics.append(metrics)
            all_metrics.append(metrics)  # æ·»åŠ åˆ°æ€»ç»“æœ

            # ä¿å­˜é¢„æµ‹ç»“æœ
            if config['testing']['save_predictions']:
                pred_path = pred_adapt_dir / f"{patient_id}_pred.nii.gz"
                save_brats_prediction(prediction, str(pred_path), threshold)

            # å¯è§†åŒ–
            if config['testing']['visualization']:
                vis_path = vis_adapt_dir / f"{patient_id}_result.png"
                visualize_result_3d(
                    image, label, prediction_cropped,
                    str(vis_path), patient_id, metrics
                )

        except Exception as e:
            print(f"\nâš ï¸  å¤„ç†é€‚åº”æ ·æœ¬ {patient_id} æ—¶å‡ºé”™: {e}")
            failed_samples.append((patient_id, 'adaptation'))
            continue

    print(f"\n  2. æµ‹è¯•å‰©ä½™æ ·æœ¬ ({len(test_eval_dataset)}ä¸ª)")

    # æµ‹è¯•å‰©ä½™æ ·æœ¬
    for idx in tqdm(range(len(test_eval_dataset)), desc='æµ‹è¯•å‰©ä½™æ ·æœ¬'):
        sample = test_eval_dataset[idx]
        original_idx = sample['original_idx']

        image = sample['image'].numpy()
        label = sample['label'].numpy()
        patient_id = sample['patient_id']
        crop_info = sample['crop_info']
        original_shape = sample['original_shape']

        try:
            start_time = time.time()

            # æ¨ç†
            if inference_mode == 'sliding_window':
                prediction_cropped = sliding_window_inference(
                    inference_model, image, window_size,
                    overlap, maml.device, threshold
                )
            else:
                prediction_cropped = center_crop_inference(
                    inference_model, image, window_size,
                    maml.device, threshold
                )

            # æ¢å¤åˆ°åŸå§‹å°ºå¯¸
            prediction = restore_to_original_size(
                prediction_cropped,
                crop_info,
                original_shape
            )

            processing_time = time.time() - start_time
            processing_times.append(processing_time)

            # è®¡ç®—æŒ‡æ ‡
            pred_logits = torch.FloatTensor(prediction_cropped)
            target_tensor = torch.FloatTensor(label).unsqueeze(0)

            metrics = compute_brats_metrics(
                pred_logits.unsqueeze(0),
                target_tensor,
                threshold
            )

            metrics['patient_id'] = patient_id
            metrics['original_idx'] = original_idx
            metrics['sample_type'] = 'test'  # æ ‡è®°ä¸ºæµ‹è¯•æ ·æœ¬
            metrics['processing_time'] = processing_time

            test_metrics.append(metrics)
            all_metrics.append(metrics)  # æ·»åŠ åˆ°æ€»ç»“æœ

            # ä¿å­˜é¢„æµ‹ç»“æœ
            if config['testing']['save_predictions']:
                pred_path = pred_test_dir / f"{patient_id}_pred.nii.gz"
                save_brats_prediction(prediction, str(pred_path), threshold)

            # å¯è§†åŒ–
            if config['testing']['visualization']:
                vis_path = vis_test_dir / f"{patient_id}_result.png"
                visualize_result_3d(
                    image, label, prediction_cropped,
                    str(vis_path), patient_id, metrics
                )

        except Exception as e:
            print(f"\nâš ï¸  å¤„ç†æµ‹è¯•æ ·æœ¬ {patient_id} æ—¶å‡ºé”™: {e}")
            failed_samples.append((patient_id, 'test'))
            continue

    # ========== æ±‡æ€»ç»“æœ ==========
    if len(all_metrics) == 0:
        print(f"âŒ  {task_name} æ²¡æœ‰æˆåŠŸå¤„ç†çš„æ ·æœ¬")
        return None

    # è®¡ç®—æ€»ä½“å¹³å‡æŒ‡æ ‡ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
    summary = {
        'task_name': task_name,
        'total_samples': total_samples,
        'adaptation_samples': len(adapt_dataset),
        'test_samples': len(test_eval_dataset),
        'successful_adaptation': len(adapt_metrics),
        'successful_test': len(test_metrics),
        'failed_samples': failed_samples,
        'adaptation_info': adaptation_info,
        'avg_processing_time': float(np.mean(processing_times)),
        'metrics': {},  # æ€»ä½“æŒ‡æ ‡
        'adaptation_metrics': {},  # é€‚åº”æ ·æœ¬æŒ‡æ ‡
        'test_metrics': {}  # æµ‹è¯•æ ·æœ¬æŒ‡æ ‡
    }

    # ========== è®¡ç®—é€‚åº”æ ·æœ¬æŒ‡æ ‡ ==========
    class_names = ['WT', 'TC', 'ET']

    # é€‚åº”æ ·æœ¬æŒ‡æ ‡
    if len(adapt_metrics) > 0:
        for name in class_names:
            dice_values = [m[name]['dice'] for m in adapt_metrics if not np.isnan(m[name]['dice'])]

            if len(dice_values) > 0:
                summary['adaptation_metrics'][name] = {
                    'dice_mean': float(np.mean(dice_values)),
                    'dice_std': float(np.std(dice_values)),
                    'dice_min': float(np.min(dice_values)),
                    'dice_max': float(np.max(dice_values)),
                    'sensitivity_mean': float(np.nanmean([m[name]['sensitivity'] for m in adapt_metrics])),
                    'specificity_mean': float(np.nanmean([m[name]['specificity'] for m in adapt_metrics])),
                    'num_samples': len(dice_values)
                }
            else:
                summary['adaptation_metrics'][name] = {
                    'dice_mean': float('nan'),
                    'dice_std': float('nan'),
                    'dice_min': float('nan'),
                    'dice_max': float('nan'),
                    'sensitivity_mean': float('nan'),
                    'specificity_mean': float('nan'),
                    'num_samples': len(adapt_metrics)
                }

        # é€‚åº”æ ·æœ¬æ€»ä½“å¹³å‡
        valid_dice_means = [summary['adaptation_metrics'][n]['dice_mean']
                            for n in class_names if not np.isnan(summary['adaptation_metrics'][n]['dice_mean'])]

        summary['adaptation_metrics']['overall'] = {
            'dice_mean': float(np.mean(valid_dice_means)) if valid_dice_means else float('nan'),
            'dice_std': float(np.std(valid_dice_means)) if valid_dice_means else float('nan')
        }

    # ========== è®¡ç®—æµ‹è¯•æ ·æœ¬æŒ‡æ ‡ ==========
    if len(test_metrics) > 0:
        for name in class_names:
            dice_values = [m[name]['dice'] for m in test_metrics if not np.isnan(m[name]['dice'])]

            if len(dice_values) > 0:
                summary['test_metrics'][name] = {
                    'dice_mean': float(np.mean(dice_values)),
                    'dice_std': float(np.std(dice_values)),
                    'dice_min': float(np.min(dice_values)),
                    'dice_max': float(np.max(dice_values)),
                    'sensitivity_mean': float(np.nanmean([m[name]['sensitivity'] for m in test_metrics])),
                    'specificity_mean': float(np.nanmean([m[name]['specificity'] for m in test_metrics])),
                    'num_samples': len(dice_values)
                }
            else:
                summary['test_metrics'][name] = {
                    'dice_mean': float('nan'),
                    'dice_std': float('nan'),
                    'dice_min': float('nan'),
                    'dice_max': float('nan'),
                    'sensitivity_mean': float('nan'),
                    'specificity_mean': float('nan'),
                    'num_samples': len(test_metrics)
                }

        # æµ‹è¯•æ ·æœ¬æ€»ä½“å¹³å‡
        valid_dice_means = [summary['test_metrics'][n]['dice_mean']
                            for n in class_names if not np.isnan(summary['test_metrics'][n]['dice_mean'])]

        summary['test_metrics']['overall'] = {
            'dice_mean': float(np.mean(valid_dice_means)) if valid_dice_means else float('nan'),
            'dice_std': float(np.std(valid_dice_means)) if valid_dice_means else float('nan')
        }

    # ========== è®¡ç®—æ€»ä½“æŒ‡æ ‡ï¼ˆå…¼å®¹æ€§ï¼‰ ==========
    for name in class_names:
        dice_values = [m[name]['dice'] for m in all_metrics if not np.isnan(m[name]['dice'])]

        if len(dice_values) > 0:
            summary['metrics'][name] = {
                'dice_mean': float(np.mean(dice_values)),
                'dice_std': float(np.std(dice_values)),
                'dice_min': float(np.min(dice_values)),
                'dice_max': float(np.max(dice_values)),
                'sensitivity_mean': float(np.nanmean([m[name]['sensitivity'] for m in all_metrics])),
                'specificity_mean': float(np.nanmean([m[name]['specificity'] for m in all_metrics]))
            }
        else:
            summary['metrics'][name] = {
                'dice_mean': float('nan'),
                'dice_std': float('nan'),
                'dice_min': float('nan'),
                'dice_max': float('nan'),
                'sensitivity_mean': float('nan'),
                'specificity_mean': float('nan')
            }

    # æ€»ä½“å¹³å‡
    valid_dice_means = [summary['metrics'][n]['dice_mean']
                        for n in class_names if not np.isnan(summary['metrics'][n]['dice_mean'])]

    summary['metrics']['overall'] = {
        'dice_mean': float(np.mean(valid_dice_means)) if valid_dice_means else float('nan'),
        'dice_std': float(np.std(valid_dice_means)) if valid_dice_means else float('nan')
    }

    # ========== æ‰“å°ç»“æœ ==========
    print(f"\n{'=' * 70}")
    print(f"{task_name} æµ‹è¯•ç»“æœæ±‡æ€»")
    print('=' * 70)
    print(f"æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"é€‚åº”æ ·æœ¬: {len(adapt_dataset)}ä¸ª (ç´¢å¼•: {sorted(adapt_indices)})")
    print(f"æµ‹è¯•æ ·æœ¬: {len(test_eval_dataset)}ä¸ª")
    print(f"æˆåŠŸæµ‹è¯•: {len(all_metrics)}/{total_samples}ä¸ª")

    if failed_samples:
        print(f"å¤±è´¥æ ·æœ¬: {failed_samples}")

    # 1. æ‰“å°é€‚åº”æ ·æœ¬ç»“æœ
    print(f"\nğŸ“Š é€‚åº”æ ·æœ¬ç»“æœ ({len(adapt_metrics)}ä¸ª):")
    if len(adapt_metrics) > 0:
        print(f"{'æŒ‡æ ‡':<15} {'WT':>10} {'TC':>10} {'ET':>10}")
        print("-" * 55)

        for metric in ['dice_mean', 'dice_std', 'sensitivity_mean', 'specificity_mean']:
            metric_name = metric.replace('_mean', '').replace('_std', ' std').title()
            values = []
            for name in class_names:
                val = summary['adaptation_metrics'][name][metric]
                values.append(f"{val:.4f}" if not np.isnan(val) else "nan")

            print(f"{metric_name:<15} {values[0]:>10} {values[1]:>10} {values[2]:>10}")

        if not np.isnan(summary['adaptation_metrics']['overall']['dice_mean']):
            print(f"\né€‚åº”æ ·æœ¬å¹³å‡Dice: {summary['adaptation_metrics']['overall']['dice_mean']:.4f}")
    else:
        print("  æ— é€‚åº”æ ·æœ¬ç»“æœ")

    # 2. æ‰“å°æµ‹è¯•æ ·æœ¬ç»“æœ
    print(f"\nğŸ“Š æµ‹è¯•æ ·æœ¬ç»“æœ ({len(test_metrics)}ä¸ª):")
    if len(test_metrics) > 0:
        print(f"{'æŒ‡æ ‡':<15} {'WT':>10} {'TC':>10} {'ET':>10}")
        print("-" * 55)

        for metric in ['dice_mean', 'dice_std', 'sensitivity_mean', 'specificity_mean']:
            metric_name = metric.replace('_mean', '').replace('_std', ' std').title()
            values = []
            for name in class_names:
                val = summary['test_metrics'][name][metric]
                values.append(f"{val:.4f}" if not np.isnan(val) else "nan")

            print(f"{metric_name:<15} {values[0]:>10} {values[1]:>10} {values[2]:>10}")

        if not np.isnan(summary['test_metrics']['overall']['dice_mean']):
            print(f"\næµ‹è¯•æ ·æœ¬å¹³å‡Dice: {summary['test_metrics']['overall']['dice_mean']:.4f}")
    else:
        print("  æ— æµ‹è¯•æ ·æœ¬ç»“æœ")

    # 3. æ‰“å°æ€»ä½“ç»“æœï¼ˆä¿æŒåŸæœ‰æ ¼å¼ï¼‰
    print(f"\nğŸ“Š æ€»ä½“ç»“æœ ({len(all_metrics)}ä¸ª):")
    print(f"{'æŒ‡æ ‡':<15} {'WT':>10} {'TC':>10} {'ET':>10}")
    print("-" * 55)

    for metric in ['dice_mean', 'dice_std', 'sensitivity_mean', 'specificity_mean']:
        metric_name = metric.replace('_mean', '').replace('_std', ' std').title()
        values = [summary['metrics'][n][metric] for n in class_names]
        print(f"{metric_name:<15} {values[0]:>10.4f} {values[1]:>10.4f} {values[2]:>10.4f}")

    if not np.isnan(summary['metrics']['overall']['dice_mean']):
        print(f"\næ€»ä½“å¹³å‡Dice: {summary['metrics']['overall']['dice_mean']:.4f}")

    print('=' * 70)

    # ========== ä¿å­˜è¯¦ç»†ç»“æœ ==========
    detailed_results = {
        'summary': summary,
        'all_metrics': all_metrics,  # æ‰€æœ‰æ ·æœ¬
        'adaptation_metrics': adapt_metrics,  # é€‚åº”æ ·æœ¬è¯¦ç»†ç»“æœ
        'test_metrics': test_metrics,  # æµ‹è¯•æ ·æœ¬è¯¦ç»†ç»“æœ
        'adaptation_indices': adapt_indices,
        'test_indices': test_eval_indices,
        'config': config['testing']
    }

    result_file = task_output_dir / f"results_{task_name}.json"
    with open(result_file, 'w') as f:
        json.dump(detailed_results, f, indent=2)

    print(f"è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {result_file}")

    # ä¹Ÿä¿å­˜å•ç‹¬çš„ç»“æœæ–‡ä»¶
    adapt_result_file = task_output_dir / f"adaptation_results_{task_name}.json"
    test_result_file = task_output_dir / f"test_results_{task_name}.json"

    with open(adapt_result_file, 'w') as f:
        json.dump({
            'summary': summary['adaptation_metrics'],
            'metrics': adapt_metrics,
            'indices': adapt_indices
        }, f, indent=2)

    with open(test_result_file, 'w') as f:
        json.dump({
            'summary': summary['test_metrics'],
            'metrics': test_metrics,
            'indices': test_eval_indices
        }, f, indent=2)

    print(f"é€‚åº”æ ·æœ¬ç»“æœ: {adapt_result_file}")
    print(f"æµ‹è¯•æ ·æœ¬ç»“æœ: {test_result_file}")

    return summary
def compare_centers(all_results):
    """
    æ¯”è¾ƒä¸åŒä¸­å¿ƒçš„æ€§èƒ½
    """
    print(f"\n{'='*70}")
    print("å¤šä¸­å¿ƒæ€§èƒ½æ¯”è¾ƒ")
    print('='*70)

    # æå–æ•°æ®
    centers = list(all_results.keys())

    print(f"{'ä¸­å¿ƒ':<20} {'æ ·æœ¬æ•°':<8} {'WT Dice':<10} {'TC Dice':<10} {'ET Dice':<10} {'å¹³å‡Dice':<10} {'é€‚åº”':<10}")
    print("-" * 80)

    for center in centers:
        result = all_results[center]
        adapted = "æ˜¯" if result['adaptation']['adapted'] else "å¦"

        print(f"{center:<20} {result['num_samples']:<8} "
              f"{result['metrics']['WT']['dice_mean']:<10.4f} "
              f"{result['metrics']['TC']['dice_mean']:<10.4f} "
              f"{result['metrics']['ET']['dice_mean']:<10.4f} "
              f"{result['metrics']['overall']['dice_mean']:<10.4f} "
              f"{adapted:<10}")

    # è®¡ç®—æ‰€æœ‰ä¸­å¿ƒçš„å¹³å‡
    overall_wt = np.mean([r['metrics']['WT']['dice_mean'] for r in all_results.values()])
    overall_tc = np.mean([r['metrics']['TC']['dice_mean'] for r in all_results.values()])
    overall_et = np.mean([r['metrics']['ET']['dice_mean'] for r in all_results.values()])
    overall_mean = np.mean([r['metrics']['overall']['dice_mean'] for r in all_results.values()])

    print("-" * 80)
    print(f"{'æ‰€æœ‰ä¸­å¿ƒå¹³å‡':<20} {'-':<8} "
          f"{overall_wt:<10.4f} "
          f"{overall_tc:<10.4f} "
          f"{overall_et:<10.4f} "
          f"{overall_mean:<10.4f} "
          f"{'-':<10}")

    print('='*70)


def test(config):
    """
    ä¸»æµ‹è¯•å‡½æ•° - æ‰€æœ‰å‚æ•°ä»é…ç½®æ–‡ä»¶è·å–
    """
    print("\n" + "=" * 70)
    print("BraTSå¤šä¸­å¿ƒMAMLå…ƒæµ‹è¯•")
    print("=" * 70)

    # éªŒè¯é…ç½®
    validate_config(config)

    # ä»é…ç½®ä¸­è·å–checkpointè·¯å¾„
    checkpoint_path = config['testing']['checkpoint']
    print(f"æ£€æŸ¥ç‚¹è·¯å¾„: {checkpoint_path}")

    # éªŒè¯æ£€æŸ¥ç‚¹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")

    # è®¾ç½®è®¾å¤‡
    device = torch.device(config['hardware']['device']
                         if torch.cuda.is_available() else 'cpu')
    print(f"è®¾å¤‡: {device}")

    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name(0)}")
        print(f"æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

    # åŠ è½½æ¨¡å‹
    print("\nåŠ è½½æ¨¡å‹...")
    model = ResUNet(
        in_channels=config['model']['in_channels'],
        out_channels=config['model']['out_channels'],
        base_channels=config['model']['base_channels']
    )

    maml = FirstOrderMAML(
        model=model,
        inner_lr=config['maml']['inner_lr'],
        outer_lr=config['maml']['outer_lr'],
        inner_steps=config['maml']['inner_steps'],
        device=device
    )

    # åŠ è½½checkpoint
    checkpoint = maml.load_checkpoint(checkpoint_path)
    print(f"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ")
    print(f"  è®­ç»ƒè½®æ•°: {checkpoint.get('epoch', 'Unknown')}")
    if 'metrics' in checkpoint:
        print(f"  è®­ç»ƒDice: {checkpoint['metrics'].get('dice_mean', 'Unknown'):.4f}")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_base_dir = Path(config['testing']['output_dir'])
    output_base_dir.mkdir(parents=True, exist_ok=True)

    # ä¿å­˜æµ‹è¯•é…ç½®
    config_save_path = output_base_dir / "test_config.yaml"
    with open(config_save_path, 'w') as f:
        yaml.dump(config, f, default_flow_style=False)

    # æµ‹è¯•æ¯ä¸ªä»»åŠ¡
    all_results = {}

    for task_name in config['testing']['test_tasks']:
        try:
            result = test_single_task(
                maml, config, task_name,
                output_base_dir
            )

            if result is not None:
                all_results[task_name] = result

        except Exception as e:
            print(f"\nâŒ {task_name} æµ‹è¯•å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # æ¯”è¾ƒä¸åŒä¸­å¿ƒ
    if len(all_results) > 1:
        compare_centers(all_results)

    # ä¿å­˜æ€»ä½“ç»“æœ
    if all_results:
        overall_results = {
            'config': config['testing'],
            'checkpoint': checkpoint_path,
            'results': all_results,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }

        overall_file = output_base_dir / "overall_results.json"
        with open(overall_file, 'w') as f:
            json.dump(overall_results, f, indent=2)

        print(f"\næ€»ä½“ç»“æœå·²ä¿å­˜åˆ°: {overall_file}")

        # æ‰“å°å…³é”®ç»“è®º
        adapted_centers = [c for c, r in all_results.items() if r['adaptation']['adapted']]
        non_adapted = [c for c, r in all_results.items() if not r['adaptation']['adapted']]

        print(f"\nğŸ“Š å…³é”®ç»“è®º:")
        print(f"  1. æµ‹è¯•äº† {len(all_results)} ä¸ªä¸­å¿ƒ")
        print(f"  2. {len(adapted_centers)} ä¸ªä¸­å¿ƒä½¿ç”¨äº†å¿«é€Ÿé€‚åº”")
        print(f"  3. æœ€ä½³æ€§èƒ½ä¸­å¿ƒ: {max(all_results.items(), key=lambda x: x[1]['metrics']['overall']['dice_mean'])[0]}")
        print(f"  4. æœ€å·®æ€§èƒ½ä¸­å¿ƒ: {min(all_results.items(), key=lambda x: x[1]['metrics']['overall']['dice_mean'])[0]}")
        print(f"  5. æ‰€æœ‰ä¸­å¿ƒå¹³å‡Dice: {np.mean([r['metrics']['overall']['dice_mean'] for r in all_results.values()]):.4f}")

    print("\n" + "=" * 70)
    print("æµ‹è¯•å®Œæˆ!")
    print("=" * 70)

    return all_results


def main():
    """ä¸»å‡½æ•° - ä»å‘½ä»¤è¡Œè·å–é…ç½®æ–‡ä»¶è·¯å¾„"""
    parser = argparse.ArgumentParser(description='BraTSå¤šä¸­å¿ƒMAMLå…ƒæµ‹è¯•')
    parser.add_argument('--config', type=str, default='config.yaml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: config.yamlï¼‰')

    args = parser.parse_args()

    # åŠ è½½é…ç½®
    config_path = args.config
    if not os.path.exists(config_path):
        print(f"é”™è¯¯: é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        print("è¯·åˆ›å»ºä¸€ä¸ªé…ç½®æ–‡ä»¶æˆ–æŒ‡å®šæ­£ç¡®çš„è·¯å¾„")
        print("ç¤ºä¾‹é…ç½®æ–‡ä»¶ç»“æ„:")
        print("""
data:
  data_root: "data"
  crop_size: [224, 224, 128]

model:
  in_channels: 4
  out_channels: 3
  base_channels: 16

maml:
  inner_lr: 0.01
  outer_lr: 0.001
  inner_steps: 5

hardware:
  device: "cuda"

testing:
  checkpoint: "checkpoints/best_model.pth"
  test_tasks: ["BraTS_Center1", "BraTS_Center2"]
  output_dir: "test_results"
  enable_adaptation: true
  adaptation_k_shot: 3
  adaptation_inner_steps: 10
  inference:
    mode: "sliding_window"
    overlap: 0.5
  threshold: 0.5
  save_predictions: true
  visualization: true
  num_visualize: 5
        """)
        sys.exit(1)

    config = load_config(config_path)

    # æ‰“å°é…ç½®
    print("\n" + "=" * 70)
    print("æµ‹è¯•é…ç½®:")
    print("=" * 70)
    print(f"é…ç½®æ–‡ä»¶: {config_path}")
    print(f"æ£€æŸ¥ç‚¹: {config['testing']['checkpoint']}")
    print(f"æµ‹è¯•ä»»åŠ¡: {config['testing']['test_tasks']}")
    print(f"è¾“å‡ºç›®å½•: {config['testing']['output_dir']}")
    print(f"å¿«é€Ÿé€‚åº”: {'å¯ç”¨' if config['testing']['enable_adaptation'] else 'ç¦ç”¨'}")
    if config['testing']['enable_adaptation']:
        print(f"  é€‚åº”æ ·æœ¬æ•°: {config['testing']['adaptation_k_shot']}")
        print(f"  é€‚åº”æ­¥æ•°: {config['testing']['adaptation_inner_steps']}")
    print(f"æ¨ç†æ¨¡å¼: {config['testing']['inference']['mode']}")
    print(f"é˜ˆå€¼: {config['testing']['threshold']}")
    print("=" * 70)

    # å¼€å§‹æµ‹è¯•
    try:
        results = test(config)

        if results:
            print("\nâœ… æµ‹è¯•æˆåŠŸå®Œæˆ!")
        else:
            print("\nâš ï¸  æµ‹è¯•å®Œæˆä½†æ— æœ‰æ•ˆç»“æœ")

    except KeyboardInterrupt:
        print("\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()